device_id[i,2] <- what
}
# Remove the test data from the dataset
daily_ema_data<-daily_ema_data[!(daily_ema_data$participant_id=="test"),]
intensive_ema_data <- merge(intensive_ema_data,device_id,by="bucket_device_id")
# Check out the missing data patterns
#raw_text_data %>%
#select(-deactivation_date_n) %>%
#missmap()
# Check out missing data patterns
#missmap(intensive_ema_data)
# Check out missing data patterns
#missmap(daily_ema_data)
# First we're going to just check out and see how many messages each participant sent
text_counts <- raw_text_data %>%
group_by(participant_id,date) %>%
tally()
text_counts %>%
ggplot(aes(x = date, y = n, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id,scales="free") +
theme(legend.position = "none")
# Now let's see what the first EMA time and date is for each participant
daily_ema_data <- daily_ema_data[!is.na(daily_ema_data$participant_id) & !is.na(daily_ema_data$bucket_device_id),]
daily_ema_data$participant_id[is.na(daily_ema_data$participant_id)] <- daily_ema_data$bucket_device_id[is.na(daily_ema_data$participant_id)]
daily_testing_buckets <- unique(daily_ema_data$bucket_device_id)
daily_device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daily_device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(daily_testing_buckets)){
what <- unique(daily_ema_data$participant_id[daily_ema_data$bucket_device_id==daily_testing_buckets[i]])
daily_device_id[i,1] <- daily_testing_buckets[i]
daily_device_id[i,2] <- what
}
daily_ema_data$timestamp_est <- as.POSIXct(daily_ema_data$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")
daily_ema_data$date <- as_date(daily_ema_data$timestamp_est)
daily_ema_data %>%
ggplot(aes(x = timestamp_est, y = daily, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
intensive_ema_data$timeCompleted <- as_datetime(as.numeric(intensive_ema_data$timeCompleted)/1000,tz="America/New_York")
intensive_ema_data %>%
ggplot(aes(x = timeCompleted, y = sad, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
# Now let's see what the first EMA time and date is for each participant
daily_ema_data <- daily_ema_data[!is.na(daily_ema_data$participant_id) & !is.na(daily_ema_data$bucket_device_id),]
daily_ema_data$participant_id[is.na(daily_ema_data$participant_id)] <- daily_ema_data$bucket_device_id[is.na(daily_ema_data$participant_id)]
daily_testing_buckets <- unique(daily_ema_data$bucket_device_id)
daily_device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daily_device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(daily_testing_buckets)){
what <- unique(daily_ema_data$participant_id[daily_ema_data$bucket_device_id==daily_testing_buckets[i]])
daily_device_id[i,1] <- daily_testing_buckets[i]
daily_device_id[i,2] <- what
}
daily_ema_data$timestamp_est <- as.POSIXct(daily_ema_data$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")
daily_ema_data$date <- as_date(daily_ema_data$timestamp_est)
daily_ema_data %>%
ggplot(aes(x = timestamp_est, y = daily, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
intensive_ema_data$timeCompleted <- as_datetime(as.numeric(intensive_ema_data$timeCompleted)/1000,tz="America/New_York")
intensive_ema_data %>%
ggplot(aes(x = timeCompleted, y = sad, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
intensive_ema_data$timeCompleted <- as_datetime(as.numeric(intensive_ema_data$timeCompleted)/1000,tz="America/New_York")
intensive_ema_data %>%
ggplot(aes(x = timeCompleted, y = sad, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
text_counts$date <- as.Date(text_counts$date, format = "%Y-%m-%d")
gam_data <- merge(text_counts, daily_ema_data, by=c("participant_id","date")) %>%
select(participant_id,date,n,site,daily,day_of_week,weekend)
gam_data <- gam_data %>%
group_by(participant_id) %>%
filter(n() >= 15)
gam_data <- gam_data[order(gam_data$participant_id, gam_data$date), ]
gam_data <- gam_data %>%
group_by(participant_id) %>%
mutate(diff_days = difftime(date, min(date),units="days"))
gam_data <- gam_data %>%
group_by(participant_id) %>%
mutate(lag_days = difftime(date, lag(date),units="days"))
gam_data$lag_days <- as.numeric(gam_data$lag_days)
gam_data <- gam_data %>%
group_by(participant_id) %>%
filter(is.na(lead(lag_days)) | !lead(lag_days)==0)
gam_data <- gam_data %>%
group_by(participant_id) %>%
mutate(lag_days = difftime(date, lag(date),units="days"))
intensive_ema_data$date <- as_date(intensive_ema_data$timeCompleted)
ema_1004 <- intensive_ema_data %>%
filter(participant_id==1004 & ema_self_initiated == FALSE)
ema_1004 <- ema_1004 %>%
mutate(start_time = timeCompleted - hours(2))
raw_text_data$date <- as_date(raw_text_data$date)
text_1004 <- raw_text_data %>%
filter(participant_id==1004)
text_1004$timestamp_est <- as.POSIXct(text_1004$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")
test <- ema_1004 %>%
left_join(text_1004,by = c("participant_id")) %>%
filter(timestamp_est >= start_time & timestamp_est < timeCompleted)
library(fuzzyjoin)
ema_1004 <- ema_1004 %>%
select(-timeInitiated,-ema_self_initiated)
huh <- fuzzy_left_join(
ema_1004,text_1004,
by = c(
"participant_id" = "participant_id",
"start_time" = "timestamp_est",
"timeCompleted" = "timestamp_est"
),
match_fun = list(`==`, `<=`, `>`)
)
gam_1004 <- huh %>%
group_by(timeCompleted,.drop=FALSE) %>%
add_tally()
gam_1004 <- gam_1004 %>%
group_by(start_time)
gam_1004 <- gam_1004 %>%
distinct(start_time, .keep_all=TRUE)
gam_1004 <- gam_1004 %>%
group_by(participant_id.x) %>%
mutate(diff_hours = difftime(timeCompleted, min(timeCompleted),units="hours"))
gam_1004 <- gam_1004 %>%
select(participant_id=participant_id.x,angry,anxious,calm,confident,happy,included,lonely,rejected,sad,stressed,supported,start_time,timeCompleted,date=date.x,weekend,n,recentContact,diff_hours)
gam_1004$log_n <- log(gam_1004$n)
head(ema_1004$timeCompleted)
head(text_1004$timestamp_est)
head(ema_1004$timeCompleted)
as_datetime(as.numeric(intensive_ema_data$timeCompleted)/1000,tz="America/New_York")
rm(list=ls())
packages <- c("rio","tidyverse","reshape","lme4","interactions","jtools","lmerTest","Amelia","mice","lavaan","semTools","janitor","stargazer","plotluck","splitstackshape","mgcv","Amelia","lubridate","here","fuzzyjoin","bit64")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, library, character.only = TRUE)
raw_text_data <- import(here("data/text_df_unique.csv"))
intensive_ema_data <- import(here("data/ema_df.csv"))
daily_ema_data <- import(here("data/daily_df.csv"))
# Missing some participant IDs so I'm moving the bucket device ID over to the NA
raw_text_data$participant_id[is.na(raw_text_data$participant_id)] <- raw_text_data$bucket_device_id[is.na(raw_text_data$participant_id)]
testing_buckets <- unique(raw_text_data$bucket_device_id)
device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(testing_buckets)){
what <- unique(raw_text_data$participant_id[raw_text_data$bucket_device_id==testing_buckets[i]])
device_id[i,1] <- testing_buckets[i]
device_id[i,2] <- what
}
# Remove the test data from the dataset
daily_ema_data<-daily_ema_data[!(daily_ema_data$participant_id=="test"),]
intensive_ema_data <- merge(intensive_ema_data,device_id,by="bucket_device_id")
# First we're going to just check out and see how many messages each participant sent
text_counts <- raw_text_data %>%
group_by(participant_id,date) %>%
tally()
text_counts %>%
ggplot(aes(x = date, y = n, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id,scales="free") +
theme(legend.position = "none")
install.packages("caret")
install.packages("xgboost")
rm(list=ls())
packages <- c("rio","tidyverse","reshape","lme4","interactions","jtools","lmerTest","Amelia","mice","lavaan","semTools","janitor","stargazer","plotluck","splitstackshape","gratia","mgcv","Amelia","lubridate","here","fuzzyjoin","Metrics")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
install.packages(setdiff(packages, rownames(installed.packages())))
}
lapply(packages, library, character.only = TRUE)
raw_text_data <- import(here("data/text_df_unique.csv"))
intensive_ema_data <- import(here("data/ema_df.csv"))
daily_ema_data <- import(here("data/daily_df.csv"))
# Missing some participant IDs so I'm moving the bucket device ID over to the NA
raw_text_data$participant_id[is.na(raw_text_data$participant_id)] <- raw_text_data$bucket_device_id[is.na(raw_text_data$participant_id)]
stuff_to_remove <- c("Send a chat","Enter message","Say something in pizza_suplex's chat","Search or type web address","Search or enter URL","Type a message","Search YouTube","Say your thing","Write a message","Shantii.thedubb","Type search keywords")
# Remove "send a chat" from thing
raw_text_data <- raw_text_data[!grepl(stuff_to_remove, raw_text_data$text),]
more_stuff_to_remove <- c("w\x95","\x95\x95\x95\x95\x95\x95\x95i\x95","Type a message\x85")
for(i in 1:10){
raw_text_data <- raw_text_data %>% filter(!str_detect(text, more_stuff_to_remove))
}
testing_buckets <- unique(raw_text_data$bucket_device_id)
device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(testing_buckets)){
what <- unique(raw_text_data$participant_id[raw_text_data$bucket_device_id==testing_buckets[i]])
device_id[i,1] <- testing_buckets[i]
device_id[i,2] <- what
}
# Remove the test data from the dataset
daily_ema_data<-daily_ema_data[!(daily_ema_data$participant_id=="test"),]
intensive_ema_data <- merge(intensive_ema_data,device_id,by="bucket_device_id")
# Check out the missing data patterns
#raw_text_data %>%
#select(-deactivation_date_n) %>%
#missmap()
# Check out missing data patterns
#missmap(intensive_ema_data)
# Check out missing data patterns
#missmap(daily_ema_data)
# First we're going to just check out and see how many messages each participant sent
text_counts <- raw_text_data %>%
group_by(participant_id,date) %>%
tally()
text_counts %>%
ggplot(aes(x = date, y = n, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id,scales="free") +
theme(legend.position = "none")
# Now let's see what the first EMA time and date is for each participant
daily_ema_data <- daily_ema_data[!is.na(daily_ema_data$participant_id) & !is.na(daily_ema_data$bucket_device_id),]
daily_ema_data$participant_id[is.na(daily_ema_data$participant_id)] <- daily_ema_data$bucket_device_id[is.na(daily_ema_data$participant_id)]
daily_testing_buckets <- unique(daily_ema_data$bucket_device_id)
daily_device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daily_device_id) <- c("bucket_device_id","participant_id")
for(i in 1:length(daily_testing_buckets)){
what <- unique(daily_ema_data$participant_id[daily_ema_data$bucket_device_id==daily_testing_buckets[i]])
daily_device_id[i,1] <- daily_testing_buckets[i]
daily_device_id[i,2] <- what
}
daily_ema_data$timestamp_est <- as.POSIXct(daily_ema_data$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")
daily_ema_data$date <- as_date(daily_ema_data$timestamp_est)
daily_ema_data %>%
ggplot(aes(x = timestamp_est, y = daily, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
intensive_ema_data$timeCompleted <- as_datetime(as.numeric(intensive_ema_data$timeCompleted)/1000,tz="America/New_York")
intensive_ema_data %>%
filter(ema_self_initiated==FALSE) %>%
ggplot(aes(x = timeCompleted, y = sad, group = participant_id)) +
stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
facet_wrap(~participant_id) +
theme(legend.position = "none")
text_counts$date <- as.Date(text_counts$date, format = "%Y-%m-%d")
gam_data <- merge(text_counts, daily_ema_data, by=c("participant_id","date")) %>%
select(participant_id,date,n,site,daily,day_of_week,weekend)
gam_data <- gam_data %>%
group_by(participant_id) %>%
filter(n() >= 15)
gam_data <- gam_data[order(gam_data$participant_id, gam_data$date), ]
gam_data <- gam_data %>%
group_by(participant_id) %>%
mutate(diff_days = difftime(date, min(date),units="days"))
gam_data <- gam_data %>%
group_by(participant_id) %>%
mutate(lag_days = difftime(date, lag(date),units="days"))
gam_data$lag_days <- as.numeric(gam_data$lag_days)
gam_data <- gam_data %>%
group_by(participant_id) %>%
filter(is.na(lead(lag_days)) | !lead(lag_days)==0)
gam_data <- gam_data %>%
group_by(participant_id) %>%
mutate(lag_days = difftime(date, lag(date),units="days"))
knitr::kable(head(gam_data))
gam_data$diff_days <- as.numeric(gam_data$diff_days)
gam_data$participant_id <- as.factor(gam_data$participant_id)
gam_data$site <- as.factor(gam_data$site)
gam_data$log_n <- log(gam_data$n)
model_1 <- gam(daily ~
s(diff_days,log_n,by=participant_id, k=20, bs=c("tp","tp")) +
s(participant_id, bs="re"),
data=gam_data,
correlation = corARMA(form = ~ 1|participant_id),
method="REML")
install.packages("e1071")
plot(model_1,scheme=2)
intensive_ema_data$date <- as_date(intensive_ema_data$timeCompleted)
ema_1004 <- intensive_ema_data %>%
filter(participant_id==1004 & ema_self_initiated == FALSE)
ema_1004 <- ema_1004 %>%
mutate(start_time = timeCompleted - hours(2))
raw_text_data$date <- as_date(raw_text_data$date)
text_1004 <- raw_text_data %>%
filter(participant_id==1004)
text_1004$timestamp_est <- as.POSIXct(text_1004$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")
test <- ema_1004 %>%
left_join(text_1004,by = c("participant_id")) %>%
filter(timestamp_est >= start_time & timestamp_est < timeCompleted)
library(fuzzyjoin)
ema_1004 <- ema_1004 %>%
select(-timeInitiated,-ema_self_initiated)
huh <- fuzzy_left_join(
ema_1004,text_1004,
by = c(
"participant_id" = "participant_id",
"start_time" = "timestamp_est",
"timeCompleted" = "timestamp_est"
),
match_fun = list(`==`, `<=`, `>`)
)
gam_1004 <- huh %>%
group_by(timeCompleted,.drop=FALSE) %>%
add_tally()
gam_1004 <- gam_1004 %>%
group_by(participant_id.x,start_time)
gam_1004_text_alt <- gam_1004 %>%
group_by(participant_id.x,start_time)
gam_1004 <- gam_1004 %>%
distinct(start_time, .keep_all=TRUE)
gam_1004 <- gam_1004 %>%
group_by(participant_id.x) %>%
mutate(diff_hours = difftime(timeCompleted, min(timeCompleted),units="hours"))
gam_1004 <- gam_1004 %>%
select(participant_id=participant_id.x,angry,anxious,calm,confident,happy,included,lonely,rejected,sad,stressed,supported,start_time,timeCompleted,date=date.x,weekend,n,recentContact,diff_hours)
gam_1004$log_n <- log(gam_1004$n)
knitr::kable(head(gam_1004))
gam_1004$diff_hours <- as.numeric(gam_1004$diff_hours)
model_2 <- gam(calm ~
s(diff_hours,log_n, k=20, bs=c("tp","tp")),
data=gam_1004,
correlation = corARMA(form = ~ 1|participant_id),
method="REML")
plot(model_2,scheme=2)
library(tidytext)
install.packages("tidytext")
library(tidytext)
text_tidy_data <- raw_text_data
text_tidy_data <- text_tidy_data %>%
group_by(participant_id) %>%
mutate(textnumber = row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
text_tidy_data$timestamp_est <- as.POSIXct(text_tidy_data$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")
#Remove Stop Words
data(stop_words)
text_tidy_data_filtered <- text_tidy_data %>%
anti_join(stop_words)
my_stop_words <- tibble(
word = c(
"im",
"0001f602",
"yeah",
"dont",
"idk",
"lol",
"0001f923",
"wanna",
"ur",
"hey",
"gonna",
"tho",
"ill",
"bc",
"ye",
"lmao",
"0001f62d",
"search",
"message",
"ima",
"cuz",
"yo",
"people",
"nah",
"gunna",
"send",
"wont",
"gotta",
"ik"
),
lexicon = "texting"
)
text_tidy_data_filtered <- text_tidy_data_filtered %>%
anti_join(my_stop_words)
texting_sentiment <- text_tidy_data_filtered %>%
inner_join(get_sentiments("bing")) %>%
count(participant_id, timestamp_est, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
text_tidy_data_filtered <- text_tidy_data_filtered %>%
left_join(texting_sentiment,by = c("participant_id","timestamp_est"))
text_tidy_data_filtered$sentiment[is.na(text_tidy_data_filtered$sentiment)] <- 0
text_tidy_data_filtered %>%
filter(participant_id==1011 | participant_id==1004) %>%
ggplot(aes(timestamp_est, sentiment, color = participant_id)) +
geom_line(show.legend = FALSE) +
geom_point(show.legend = FALSE) +
facet_wrap(~participant_id, ncol = 2, scales = "free_x")
daily_text_sentiment <- text_tidy_data_filtered %>%
group_by(participant_id,date) %>%
count(daily_sentiment=mean(sentiment))
gam_data_sentiment <- merge(daily_text_sentiment, daily_ema_data, by=c("participant_id","date")) %>%
select(participant_id,date,daily_sentiment,n,site,daily,day_of_week,weekend)
gam_data_sentiment <- gam_data_sentiment %>%
group_by(participant_id) %>%
filter(n()>= 15)
gam_data_sentiment <- gam_data_sentiment[order(gam_data_sentiment$participant_id, gam_data_sentiment$date), ]
gam_data_sentiment <- gam_data_sentiment %>%
group_by(participant_id) %>%
mutate(diff_days = difftime(date, min(date),units="days"))
gam_data_sentiment <- gam_data_sentiment %>%
group_by(participant_id) %>%
mutate(lag_days = difftime(date, lag(date),units="days"))
gam_data_sentiment$lag_days <- as.numeric(gam_data_sentiment$lag_days)
gam_data_sentiment <- gam_data_sentiment %>%
group_by(participant_id) %>%
filter(is.na(lead(lag_days)) | !lead(lag_days)==0)
gam_data_sentiment <- gam_data_sentiment %>%
group_by(participant_id) %>%
mutate(lag_days = difftime(date, lag(date),units="days"))
gam_data_sentiment$participant_id <- as.factor(gam_data_sentiment$participant_id)
gam_data_sentiment$diff_days <- as.numeric(gam_data_sentiment$diff_days)
gam_data_sentiment$log_n <- log(gam_data_sentiment$n)
func <- function(xx)
{
return(data.frame(COR = cor(xx$daily_sentiment, xx$daily), LENG =length(xx$log_n)))
}
library(plyr)
plyr::ddply(gam_data_sentiment, .(participant_id), func)
library(apaTables)
gam_data_sentiment %>%
apa.cor.table()
cor(gam_data_sentiment$daily_sentiment,gam_data_sentiment$daily)
model_3 <- gam(daily ~
s(log_n,daily_sentiment,by=participant_id, k=10, bs=c("tp"),m=2)+
s(participant_id, bs="re"),
data=gam_data_sentiment,
correlation = corARMA(form = ~ diff_days|participant_id),
method="REML")
plot(model_3,scheme=2)
library(e1071)
model <- svm(daily ~ participant_id + daily_text_sentiment + log_n + diff_days , data)
model <- svm(daily ~ participant_id + daily_text_sentiment + log_n + diff_days , gam_data_sentiment)
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days , gam_data_sentiment)
predictedY <- predict(model, data)
model <- svm(daily ~ haily_sentiment, gam_data_sentiment)
model <- svm(daily ~ daily_sentiment, gam_data_sentiment)
predictedY <- predict(model, data)
predictedY <- predict(model, gam_data_sentiment)
predictedY <- predict(model, gam_data_sentiment)
library(Metrics)
rmse(gam_data_sentiment$daily,predictedY)
predictedY
gam_data_sentiment$daily
rmse(gam_data_sentiment["daily"],predictedY)
gam_data_sentiment["daily"]
rmse(gam_data_sentiment[["daily"]],predictedY)
gam_data_sentiment[["daily"]]
length(gam_data_sentiment[["daily"]])
predictedY
rmse(gam_data_sentiment[["daily"]],predictedY)
model <- svm(daily ~  daily_text_sentiment + log_n + diff_days , gam_data_sentiment)
predictedY <- predict(model, gam_data_sentiment)
model <- svm(daily ~  daily_text_sentiment + log_n + diff_days , gam_data_sentiment)
model <- svm(daily ~ participant_id + daily_text_sentiment + log_n + diff_days , gam_data_sentiment)
model <- svm(daily ~ participant_id + daily_text_sentiment + log_n + diff_days , gam_data_sentiment)
predictedY <- predict(model, gam_data_sentiment)
rmse(gam_data_sentiment[["daily"]],predictedY)
model <- svm(daily ~ diff_days , gam_data_sentiment)
model <- svm(daily ~ daily_text_sentiment + log_n + diff_days , gam_data_sentiment)
model <- svm(daily ~ daily_text_sentiment , gam_data_sentiment)
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days , gam_data_sentiment)
predictedY <- predict(model, gam_data_sentiment)
rmse(gam_data_sentiment["daily"],predictedY)
predictedY <- predict(model, gam_data_sentiment)
rmse(gam_data_sentiment["daily"],predictedY)
gam_data_sentiment["daily"]
rmse(gam_data_sentiment[["daily"]],predictedY)
model <- svm(daily ~  daily_sentiment + log_n + diff_days , gam_data_sentiment)
predictedY <- predict(model, gam_data_sentiment)
rmse(gam_data_sentiment[["daily"]],predictedY)
text_train <- gam_data_sentiment %>%
group_by(participant_id) %>%
filter(row_number() < (n()-3))
text_test <- gam_data_sentiment %>%
group_by(participant_id) %>%
filter(row_number() >= (n()-3))
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days + we, text_train)
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days + wekend, text_train)
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days + weekend, text_train)
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days + weekend, text_train)
predictedY <- predict(model, gam_data_sentiment)
rmse(gam_data_sentiment[["daily"]],predictedY)
predictedY <- predict(model, text_test)
rmse(gam_data_sentiment[["daily"]],predictedY)
model <- svm(daily ~ daily_sentiment + log_n + diff_days + weekend, text_train)
predictedY <- predict(model, text_test)
rmse(gam_data_sentiment[["daily"]],predictedY)
model <- svm(daily ~ participant_id + daily_sentiment + log_n + diff_days + weekend, text_train)
predictedY <- predict(model, text_test)
rmse(gam_data_sentiment[["daily"]],predictedY)
model_4 <- gam(daily ~
s(log_n,daily_sentiment,by=participant_id, k=10, bs=c("tp"),m=2)+
s(participant_id, bs="re"),
data=text_train,
correlation = corARMA(form = ~ diff_days|participant_id),
method="REML")
model_4_predicted <- predict(model_4,text_test,type="response")
library(Metrics)
rmse(model_4_predicted,text_test$daily)
tuneResult <- tune(svm, daily ~ participant_id + daily_sentiment + log_n + diff_days + weekend,  data = text_train,
ranges = list(epsilon = seq(0,0.2,0.01), cost = 2^(2:9))
)
print(tuneResult)
plot(tuneResult)
tunedModel <- tuneResult$best.model
tunedModelY <- predict(tunedModel, text_test)
rmse(text_test[["daily"]],predictedY)
rmse(text_test[["daily"]],tunedModelY)
model <- svm(daily ~ participant_id + daily_sentiment + n + diff_days + weekend, text_train)
predictedY <- predict(model, text_test)
rmse(text_test[["daily"]],predictedY)
tuneResult <- tune(svm, daily ~ participant_id + daily_sentiment + n + diff_days + weekend,  data = text_train,
ranges = list(epsilon = seq(0,0.2,0.01), cost = 2^(2:9))
)
