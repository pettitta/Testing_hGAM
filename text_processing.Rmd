---
title: "Text_processing"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())
packages <- c("rio","tidyverse","reshape","lme4","interactions","jtools","lmerTest","Amelia","mice","lavaan","semTools","janitor","stargazer","plotluck","splitstackshape","gratia","mgcv","Amelia","lubridate","here","fuzzyjoin","Metrics","readxl","tidytext")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))  
}
lapply(packages, library, character.only = TRUE)

```

```{r reading the data, echo=FALSE,message=FALSE,warning=FALSE}
#raw_text_data <- import(here("data/text_df_unique.csv"))
intensive_ema_data <- import(here("data/ema_df.csv"))
#daily_ema_data <- import(here("data/daily_df.csv"))
raw_text_data <- read_excel(here("data/maps_text_unique_nopw.xlsx"))
daily_ema_data <- read_excel(here("data/maps_daily_nopw.xlsx"))



# Missing some participant IDs so I'm moving the bucket device ID over to the NA
raw_text_data$participant_id[is.na(raw_text_data$participant_id)] <- raw_text_data$bucket_device_id[is.na(raw_text_data$participant_id)]

stuff_to_remove <- c("Send a chat","Enter message","Say something in pizza_suplex's chat","Search or type web address","Search or enter URL","Type a message","Search YouTube","Say your thing","Write a message","Shantii.thedubb","Type search keywords")

# Remove "send a chat" from thing

raw_text_data <- raw_text_data[!grepl(stuff_to_remove, raw_text_data$text),]


more_stuff_to_remove <- c("w\x95","\x95\x95\x95\x95\x95\x95\x95i\x95","Type a message\x85")

for(i in 1:10){
  raw_text_data <- raw_text_data %>% filter(!str_detect(text, more_stuff_to_remove))
}


testing_buckets <- unique(raw_text_data$bucket_device_id)

device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(device_id) <- c("bucket_device_id","participant_id")

for(i in 1:length(testing_buckets)){
  what <- unique(raw_text_data$participant_id[raw_text_data$bucket_device_id==testing_buckets[i]])
  device_id[i,1] <- testing_buckets[i]
  device_id[i,2] <- what
}

# Remove the test data from the dataset
daily_ema_data<-daily_ema_data[!(daily_ema_data$participant_id=="test"),]

intensive_ema_data <- merge(intensive_ema_data,device_id,by="bucket_device_id")

```



```{r, echo=FALSE,message=FALSE,warning=FALSE}
# Check out the missing data patterns 
#raw_text_data %>%
  #select(-deactivation_date_n) %>%
  #missmap()

# Check out missing data patterns
#missmap(intensive_ema_data)

# Check out missing data patterns
#missmap(daily_ema_data)
```

# Text data

Let's get a tally of the raw text chunks per participant

```{r initial processing of the data, echo=FALSE,message=FALSE,warning=FALSE,warning=FALSE}
# First we're going to just check out and see how many messages each participant sent

text_counts <- raw_text_data %>%
  group_by(participant_id,date) %>%
  tally()

text_counts %>%
  ggplot(aes(x = date, y = n, group = participant_id)) +
  stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
  facet_wrap(~participant_id,scales="free") + 
  theme(legend.position = "none")

```

# Daily EMAs

Let's see how many participants responded to the daily EMA data

```{r, processing the daily EMA data, echo=FALSE,message=FALSE,warning=FALSE,warning=FALSE}
# Now let's see what the first EMA time and date is for each participant

daily_ema_data <- daily_ema_data[!is.na(daily_ema_data$participant_id) & !is.na(daily_ema_data$bucket_device_id),]


daily_ema_data$participant_id[is.na(daily_ema_data$participant_id)] <- daily_ema_data$bucket_device_id[is.na(daily_ema_data$participant_id)]


daily_testing_buckets <- unique(daily_ema_data$bucket_device_id)

daily_device_id <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daily_device_id) <- c("bucket_device_id","participant_id")

for(i in 1:length(daily_testing_buckets)){
  what <- unique(daily_ema_data$participant_id[daily_ema_data$bucket_device_id==daily_testing_buckets[i]])
  daily_device_id[i,1] <- daily_testing_buckets[i]
  daily_device_id[i,2] <- what
}

daily_ema_data$timestamp_est <- as.POSIXct(daily_ema_data$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")

daily_ema_data$date <- as_date(daily_ema_data$timestamp_est)


daily_ema_data %>%
  ggplot(aes(x = timestamp_est, y = daily, group = participant_id)) +
  stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
  facet_wrap(~participant_id) + 
  theme(legend.position = "none")



```

# Intensive
Now let's see how many participants responded to the intensive EMA daat

```{r processing intensive EMA data, echo=FALSE,message=FALSE,warning=FALSE}
intensive_ema_data$timeCompleted <- as_datetime(as.numeric(intensive_ema_data$timeCompleted)/1000,tz="America/New_York")

intensive_ema_data %>%
  filter(ema_self_initiated==FALSE) %>%
  ggplot(aes(x = timeCompleted, y = sad, group = participant_id)) +
  stat_summary(aes(group = participant_id,color=participant_id), geom = "line", fun.y = mean, size = .5) +
  facet_wrap(~participant_id) + 
  theme(legend.position = "none")


```

```{r hGAM data processing, echo=FALSE,message=FALSE,warning=FALSE}
text_counts$date <- as.Date(text_counts$date, format = "%Y-%m-%d")
gam_data <- merge(text_counts, daily_ema_data, by=c("participant_id","date")) %>%
  select(participant_id,date,n,site,daily,day_of_week,weekend)

gam_data <- gam_data %>%
  group_by(participant_id) %>%
  filter(n() >= 15)

gam_data <- gam_data[order(gam_data$participant_id, gam_data$date), ]

gam_data <- gam_data %>%
  group_by(participant_id) %>%
  mutate(diff_days = difftime(date, min(date),units="days"))

gam_data <- gam_data %>%
  group_by(participant_id) %>%
  mutate(lag_days = difftime(date, lag(date),units="days"))

gam_data$lag_days <- as.numeric(gam_data$lag_days)

gam_data <- gam_data %>% 
  group_by(participant_id) %>% 
  filter(is.na(lead(lag_days)) | !lead(lag_days)==0)

gam_data <- gam_data %>%
  group_by(participant_id) %>%
  mutate(lag_days = difftime(date, lag(date),units="days"))

```

# hGAM data setup

```{r showing the data, echo=FALSE,message=FALSE,warning=FALSE}
knitr::kable(head(gam_data))
```

```{r log transform data, echo=FALSE,message=FALSE,warning=FALSE}
gam_data$diff_days <- as.numeric(gam_data$diff_days)

gam_data$participant_id <- as.factor(gam_data$participant_id)

gam_data$site <- as.factor(gam_data$site)

gam_data$log_n <- log(gam_data$n)

```

# Running the hGAMbit
Show us that model!

```{r run the hGAM,message=FALSE,warning=FALSE}
model_1 <- gam(daily ~ 
                  s(diff_days,log_n,by=participant_id, k=20, bs=c("tp","tp")) + 
                  s(participant_id, bs="re"), 
                  data=gam_data,
                  correlation = corARMA(form = ~ 1|participant_id),
                  method="REML")

plot(model_1,scheme=2)
```

# Intensive EMA hGAM

```{r process intensive EMA and text, echo=FALSE,message=FALSE,warning=FALSE}
intensive_ema_data$date <- as_date(intensive_ema_data$timeCompleted)

ema_1004 <- intensive_ema_data %>%
  filter(participant_id==1004 & ema_self_initiated == FALSE) 

ema_1004 <- ema_1004 %>%
  mutate(start_time = timeCompleted - hours(2))

raw_text_data$date <- as_date(raw_text_data$date)

text_1004 <- raw_text_data %>%
  filter(participant_id==1004)

text_1004$timestamp_est <- as.POSIXct(text_1004$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")

test <- ema_1004 %>%
  left_join(text_1004,by = c("participant_id")) %>%
  filter(timestamp_est >= start_time & timestamp_est < timeCompleted) 
library(fuzzyjoin)

ema_1004 <- ema_1004 %>%
  select(-timeInitiated,-ema_self_initiated)

huh <- fuzzy_left_join(
  ema_1004,text_1004,
  by = c(
    "participant_id" = "participant_id",
    "start_time" = "timestamp_est",
    "timeCompleted" = "timestamp_est"
    ),
  match_fun = list(`==`, `<=`, `>`)
  ) 

gam_1004 <- huh %>%
  group_by(timeCompleted,.drop=FALSE) %>%
  add_tally()

gam_1004 <- gam_1004 %>%
  group_by(participant_id.x,start_time)
gam_1004_text_alt <- gam_1004 %>%
  group_by(participant_id.x,start_time)
gam_1004 <- gam_1004 %>% 
  distinct(start_time, .keep_all=TRUE)

gam_1004 <- gam_1004 %>%
  group_by(participant_id.x) %>%
  mutate(diff_hours = difftime(timeCompleted, min(timeCompleted),units="hours"))

gam_1004 <- gam_1004 %>%
  select(participant_id=participant_id.x,angry,anxious,calm,confident,happy,included,lonely,rejected,sad,stressed,supported,start_time,timeCompleted,date=date.x,weekend,n,recentContact,diff_hours)

gam_1004$log_n <- log(gam_1004$n)

```

Let's take a look at the data structure

```{r check out the gam_1004 data, echo=FALSE,message=FALSE,warning=FALSE}

knitr::kable(head(gam_1004))

```

# Is this just a hGAMe 2 you?
Let's bring out our second model!

```{r,echo=FALSE}

gam_1004$diff_hours <- as.numeric(gam_1004$diff_hours)



model_2 <- gam(calm ~ 
                  s(diff_hours,log_n, k=20, bs=c("tp","tp")),
                  data=gam_1004,
                  correlation = corARMA(form = ~ 1|participant_id),
                  method="REML")

plot(model_2,scheme=2)

```


```{r tidy text, echo=FALSE}

library(tidytext)
library(dplyr)
text_tidy_data <- raw_text_data

text_tidy_data <- text_tidy_data %>%
  group_by(participant_id) %>%
  mutate(textnumber = row_number()) %>%
  ungroup() %>%
  unnest_tokens(word, text)

text_tidy_data$timestamp_est <- as.POSIXct(text_tidy_data$timestamp_est, format="%Y-%m-%d %H:%M:%S",tz="America/New_York")

#Remove Stop Words
data(stop_words)

text_tidy_data_filtered <- text_tidy_data %>%
  anti_join(stop_words)



my_stop_words <- tibble(
  word = c(
    "im",
    "0001f602",
    "yeah",
    "dont",
    "idk",
    "lol",
    "0001f923",
    "wanna",
    "ur",
    "hey",
    "gonna",
    "tho",
    "ill",
    "bc",
    "ye",
    "lmao",
    "0001f62d",
    "search",
    "message",
    "ima",
    "cuz",
    "yo",
    "people",
    "nah",
    "gunna",
    "send",
    "wont",
    "gotta",
    "ik"
  ),
  lexicon = "texting"
)

text_tidy_data_filtered <- text_tidy_data_filtered %>%
  anti_join(my_stop_words)

texting_sentiment <- text_tidy_data_filtered %>%
  inner_join(get_sentiments("bing")) %>%
  count(participant_id, timestamp_est, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

text_tidy_data_filtered <- text_tidy_data_filtered %>%
  left_join(texting_sentiment,by = c("participant_id","timestamp_est"))

text_tidy_data_filtered$sentiment[is.na(text_tidy_data_filtered$sentiment)] <- 0


text_tidy_data_filtered %>%
  filter(participant_id==1011 | participant_id==1004) %>%
  ggplot(aes(timestamp_est, sentiment, color = participant_id)) +
  geom_line(show.legend = FALSE) +
  geom_point(show.legend = FALSE) + 
  facet_wrap(~participant_id, ncol = 2, scales = "free_x")

```


```{r join sentiment and daily EMA, echo=FALSE}

daily_text_sentiment <- text_tidy_data_filtered %>%
  group_by(participant_id,date) %>%
  count(daily_sentiment=mean(sentiment))


gam_data_sentiment <- merge(daily_text_sentiment, daily_ema_data, by=c("participant_id","date")) %>%
  select(participant_id,date,daily_sentiment,n,site,daily,day_of_week,weekend)

gam_data_sentiment <- gam_data_sentiment %>%
  group_by(participant_id) %>%
  filter(n()>=5)

gam_data_sentiment <- gam_data_sentiment[order(gam_data_sentiment$participant_id, gam_data_sentiment$date), ]

gam_data_sentiment <- gam_data_sentiment %>%
  group_by(participant_id) %>%
  mutate(diff_days = 1:n())

gam_data_sentiment <- gam_data_sentiment %>%
  group_by(participant_id) %>%
  mutate(lag_days = difftime(date, lag(date),units="days"))

gam_data_sentiment$lag_days <- as.numeric(gam_data_sentiment$lag_days)

gam_data_sentiment <- gam_data_sentiment %>% 
  group_by(participant_id) %>% 
  filter(is.na(lead(lag_days)) | !lead(lag_days)==0)

gam_data_sentiment <- gam_data_sentiment %>%
  group_by(participant_id) %>%
  mutate(lag_days = difftime(date, lag(date),units="days"))

gam_data_sentiment <- gam_data_sentiment %>%
  filter(participant_id != 1006)

```



```{r}
gam_data_sentiment$participant_id <- as.factor(gam_data_sentiment$participant_id)

gam_data_sentiment$diff_days <- as.numeric(gam_data_sentiment$diff_days)

gam_data_sentiment$log_n <- log(gam_data_sentiment$n)



func <- function(xx)
{
return(data.frame(COR = cor(xx$daily_sentiment, xx$daily), LENG =length(xx$log_n)))
}
library(plyr)
plyr::ddply(gam_data_sentiment, .(participant_id), func)
library(apaTables)

gam_data_sentiment %>%
  apaTables::apa.cor.table()

cor(gam_data_sentiment$daily_sentiment,gam_data_sentiment$daily)

```



```{r}

model_3 <- gam(daily ~ 
                  s(log_n,daily_sentiment,by=participant_id, k=10, bs=c("tp"),m=2)+
                  s(participant_id, bs="re"), 
                  data=gam_data_sentiment,
                  correlation = corARMA(form = ~ diff_days|participant_id),
                  method="REML")
plot(model_3,scheme=2)
```


```{r}
stuff <- transform(gam_data_sentiment, modG = predict(model_3, type="response"))



library(viridis)

test_1 <-ggplot(data=stuff, aes(x=log_n, y=daily_sentiment, fill=modG,color=modG)) +
  geom_tile(size=5) +
  facet_wrap(~ participant_id) +
  scale_fill_viridis("Predicted Daily") +
  scale_color_viridis("Predicted Daily") +
  labs(x = "Number of Texts", y = "Sentiment") +
  theme(legend.position="right")

test_2 <- ggplot(data=stuff, aes(x=log_n, y=daily_sentiment, fill=daily,color=daily)) +
  geom_tile(size=5) +
  facet_wrap(~ participant_id) +
  scale_fill_viridis("Actual Daily") +
  scale_color_viridis("Actual Daily") +
  labs(x = "Number of Texts", y = "Sentiment") +
  theme(legend.position="right")

library(cowplot)
plot_grid(test_1, test_2, 
          ncol=1, 
          align="vh", 
          axis = "lrtb",
          labels=c("A","B"), 
          rel_heights= c(1,1))

ggplot(data=stuff, aes(x=modG, y=daily)) +
  facet_wrap(~ participant_id) +
  geom_point(alpha=0.1) +
  geom_abline() +
  labs(x="Predicted count (model *GS*)", y= "Observed count")


```

```{r}


gam_data_sentiment$weekend <- as.factor(gam_data_sentiment$weekend)

#text_train <- gam_data_sentiment %>% 
   #group_by(participant_id) %>% 
   #filter(row_number() < (n()-3))

text_train <- gam_data_sentiment %>% 
   group_by(participant_id) %>% 
   filter(if (n() >= 15) row_number() < (n()-3) else row_number() <= (n()-0))

text_test <- gam_data_sentiment %>%
  group_by(participant_id) %>%
  filter(n() >= 15)

text_test <- text_test %>% 
   group_by(participant_id) %>% 
   filter(row_number() >= (n()-3))










model_4 <- gam(daily ~ weekend + 
                  s(log_n,daily_sentiment, k=10, bs=c("sos"))+
                  s(participant_id, bs="re"), 
                  data=text_train,
                  correlation = corARMA(form = ~ diff_days|participant_id),
                  method="REML")

model_4_predicted <- predict(model_4,text_test,type="response")

library(Metrics)

rmse(model_4_predicted,text_test$daily)


text_test$predicted <- model_4_predicted


model_5 <- gam(daily ~ 
                  1 + s(participant_id, bs="re"), 
                  data=text_train,
                  correlation = corARMA(form = ~ diff_days|participant_id),
                  method="REML")

model_5_predicted <- predict(model_5,text_test,type="response")

rmse(model_5_predicted,text_test$daily)


model_5_predicted <- predict(model_5,text_test,type="response")


text_test <- transform(text_test, mod4 = predict(model_4,text_test,type="response"))

library(viridis)
text_test <- transform(text_test, mod5 = predict(model_5,text_test,type="response"))


test_1 <-ggplot(data=text_test, aes(x=log_n, y=daily_sentiment, fill=mod4,color=mod4)) +
  geom_tile(size=5) +
  facet_wrap(~ participant_id) +
  scale_fill_viridis("Predicted Daily") +
  scale_color_viridis("Predicted Daily") +
  labs(x = "Number of Texts", y = "Sentiment") +
  theme(legend.position="right")

test_2 <-ggplot(data=text_test, aes(x=log_n, y=daily_sentiment, fill=mod5,color=mod5)) +
  geom_tile(size=5) +
  facet_wrap(~ participant_id) +
  scale_fill_viridis("Predicted Daily") +
  scale_color_viridis("Predicted Daily") +
  labs(x = "Number of Texts", y = "Sentiment") +
  theme(legend.position="right")

test_3 <- ggplot(data=text_test, aes(x=log_n, y=daily_sentiment, fill=daily,color=daily)) +
  geom_tile(size=5) +
  facet_wrap(~ participant_id) +
  scale_fill_viridis("Actual Daily") +
  scale_color_viridis("Actual Daily") +
  labs(x = "Number of Texts", y = "Sentiment") +
  theme(legend.position="right")

plot_grid(test_1, test_3, 
          ncol=1, 
          align="vh", 
          axis = "lrtb",
          labels=c("A","B"), 
          rel_heights= c(1,1))

```

```{r}
model_4 <- gam(daily ~ weekend + 
                  s(log_n,daily_sentiment, by=participant_id, k=10, bs=c("ts"))+
                  s(participant_id, bs="re"), 
                  data=text_train,
                  correlation = corARMA(form = ~ diff_days|participant_id),
                  method="REML")

plot(model_4)
```


```{r}

participant_gam_data_sentiment <- gam_data_sentiment %>%
  filter(participant_id==1006)

model_4 <- gam(daily ~ 
                  s(daily_sentiment,n, k=10, bs=c("tp"),m=2),                  
                  data=participant_gam_data_sentiment,
                  correlation = corARMA(form = ~ diff_days|participant_id),
                  method="REML")


draw(model_4)

stuff_1 <- transform(participant_gam_data_sentiment, modG = predict(model_4, type="response"))

ggplot(stuff_1, aes(x=modG, y=daily)) +
  facet_wrap(~participant_id) +
  geom_point(alpha=0.1) +
  geom_abline() +
  labs(x="Predicted daily", y="Observed observed")



```



```{r}
library(e1071)

model <- svm(daily ~ participant_id + daily_sentiment + n + diff_days + weekend, text_train)
predictedY <- predict(model, text_test)

rmse(text_test[["daily"]],predictedY)

tuneResult <- tune(svm, daily ~ participant_id + daily_sentiment + n + diff_days + weekend,  data = text_train,
                   ranges = list(epsilon = seq(0,0.2,0.01), cost = 2^(2:9))
) 
 
print(tuneResult)
plot(tuneResult)

tunedModel <- tuneResult$best.model
tunedModelY <- predict(tunedModel, text_test) 

rmse(text_test[["daily"]],tunedModelY)

plot(text_test$daily_sentiment,text_test$daily)

points(text_test$daily_sentiment,tunedModelY, col = "red", pch=4)

library(reticulate)

py_install("tzlocal")
use_condaenv("r-reticulate")

```


Let's put the data together in a new way, with a daily score associated with each message.

```{r}
full_data <- merge(raw_text_data, daily_ema_data, by=c("participant_id","date"))

write.csv(full_data,'data/full_daily_data.csv')

```



```{python}
import pandas as pd
import rpy2.robjects as ro
from rpy2.robjects.packages import importr
from rpy2.robjects import pandas2ri
pandas2ri.activate()


f1=pandas2ri.ri2py_dataframe(text_train)

#pd_df = pandas2ri.ri2py_dataframe(text_train)
```

